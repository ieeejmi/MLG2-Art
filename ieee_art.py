# -*- coding: utf-8 -*-
"""IEEE Art.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WuEIlYyF7pY-T4QKtGN0DbzBPslEqhOh
"""

import cv2
import keras
import os
import numpy as np 
import pandas as pd
import tensorflow as tf
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score
from sklearn.metrics import classification_report
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten,BatchNormalization
from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D
from keras.utils import to_categorical
from keras.preprocessing import image
from keras.layers import Input
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

df = pd.read_csv('gdrive/My Drive/ArtData/artists.csv')
df.head()

by_artist = df[['name', 'paintings']].groupby(['name'], as_index = False).sum()
name_top = by_artist.sort_values('paintings', ascending = False)[:50]
name_top

import glob
folders = glob.glob('gdrive/My Drive/ArtData/images/images/*')

Images = []
Labels = []
for folder in folders:
    for f in glob.glob(folder+'/*.jpg'):
        Images.append(f)
        Labels.append(folder.split('/')[-1])

data = {'Artwork': Images, 'Artist': Labels}
df = pd.DataFrame(data)
df.head()

df = df.sample(frac=1).reset_index(drop = True)

df.head()

img = cv2.imread(df['Artwork'].iloc[0])
plt.imshow(img)
print(str(img.shape)+" Artist : "+str(df['Artist'].iloc[0]))

from keras.preprocessing.image import ImageDataGenerator
train_gen = ImageDataGenerator(rescale=1./255., zoom_range=0.2, rotation_range=0.2, horizontal_flip=True, 
                               vertical_flip=True,shear_range=0.2, validation_split=0.25)

train_generator = train_gen.flow_from_dataframe(df, directory='', x_col='Artwork', y_col='Artist', batch_size=32,
                                                subset="training", seed=42, target_size=(299,299), shuffle=True)

valid_generator = train_gen.flow_from_dataframe(df, directory='', x_col='Artwork', y_col='Artist', batch_size=32,
                                                subset="validation", seed=42, target_size=(299,299), shuffle=True)

from keras.models import Model
from keras.applications import InceptionResNetV2
baseModel = InceptionResNetV2(weights="imagenet", include_top=False,
	input_tensor=Input(shape=(299, 299, 3)))

x = baseModel.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
predictions = Dense(50, activation="softmax")(x)

'''headModel = baseModel.output
headModel = GlobalAveragePooling2D()(headModel)
headModel = Flatten(name="flatten")(headModel)
headModel = Dense(1024, activation='relu')(headModel)
headModel = Dropout(0.5)(headModel)
headModel = Dense(512, activation='relu')(headModel)
headModel = Dropout(0.2)(headModel)
headModel = Dense(256, activation='relu')(headModel)
headModel = Dense(50, activation='softmax')(headModel)'''
 
model = Model(inputs=baseModel.input, outputs=predictions)
model.summary()

keras_callbacks   = [
      EarlyStopping(monitor='val_loss', verbose=1,patience=3, mode='min')
]

from keras import optimizers 
model.compile(loss ='categorical_crossentropy',optimizer = optimizers.Adam(lr=0.0001),
              metrics=['accuracy'])

history = model.fit(train_generator,steps_per_epoch = train_generator.n//train_generator.batch_size,
                              validation_data= valid_generator,validation_steps= valid_generator.n//valid_generator.batch_size
                              ,epochs = 50,callbacks=keras_callbacks)

score = model.evaluate(valid_generator, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

predictions = model.predict(valid_generator)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import seaborn as sns
labels=np.argmax(y_test, axis=1)
pred=np.argmax(predictions, axis=1)

target_names=['Covid', 'Normal']
con_mat = confusion_matrix(labels, pred)
con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)
 
con_mat_df = pd.DataFrame(con_mat_norm,
                     index = target_names, 
                     columns = target_names)
figure = plt.figure(figsize=(8, 8))
sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.BuPu)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()

print("Precision Score : ",precision_score(fi1, fi, pos_label=arr[0], average='binary'))
print("Recall Score : ",recall_score(fi1, fi, pos_label=arr[0],average='binary'))
print('Accuracy Score : ' + str(accuracy_score(fi1,fi)))
print('F1 Score : ' + str(f1_score(fi1,fi, pos_label=arr[0],average='binary')))

print('Classification Report')
target_names = ['Covid', 'Normal']
print(classification_report(fi1, fi, target_names=target_names))

cm1=confusion_matrix(labels,pred)
sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])
print('Sensitivity : ', sensitivity1 )

specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])
print('Specificity : ', specificity1)